{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84893b22-53af-41d1-a2c1-ccb7ebbf2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio.PDB import PDBParser\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c979618c-2aed-43f0-9415-23cc144c549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOXEL_SIZE = 1.0  # Å\n",
    "GRID_SIZE = 32  # 32x32x32\n",
    "ATOM_TYPES = ['C', 'N', 'O', 'S']  # 주요 원자 종류 (채널)\n",
    "CHANNELS = len(ATOM_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0358a508-a3be-4f51-aec2-52c440e89c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atom_channel(atom_name):\n",
    "    for i, t in enumerate(ATOM_TYPES):\n",
    "        if atom_name.startswith(t):\n",
    "            return i\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3e3b89f-9805-44fa-bb45-f273eae14dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure_coords(pdb_file):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('mol', pdb_file)\n",
    "    atoms = []\n",
    "    for atom in structure.get_atoms():\n",
    "        pos = atom.get_coord()\n",
    "        name = atom.element.strip()\n",
    "        atoms.append((pos, name))\n",
    "    return atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b554c664-0f25-4ecf-a7ee-214a4e95269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ligand_center(ligand_pdb_path, ligand_resname='UNK'):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('ligand', ligand_pdb_path)\n",
    "    \n",
    "    coords = []\n",
    "    \n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                if residue.get_resname() == ligand_resname:\n",
    "                    for atom in residue:\n",
    "                        coords.append(atom.coord)\n",
    "\n",
    "    if len(coords) == 0:\n",
    "        raise ValueError(f\"No ligand atoms found with resname {ligand_resname}\")\n",
    "    \n",
    "    coords = np.array(coords)\n",
    "    center = coords.mean(axis=0)\n",
    "    \n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d37749f-95d0-4a23-9488-479332c0be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_voxel_grid(atom_list, center, grid_size=32, voxel_size=1.0):\n",
    "    # grid 0으로 초기화\n",
    "    grid = np.zeros((CHANNELS, grid_size, grid_size, grid_size), dtype=np.float32)\n",
    "    half = grid_size * voxel_size / 2\n",
    "    for pos, name in atom_list:\n",
    "        x, y, z = pos - center + half\n",
    "        i, j, k = (int(x//voxel_size), int(y//voxel_size), int(z//voxel_size))    #위치 좌표를 grid index로 변환\n",
    "        ch = get_atom_channel(name)\n",
    "        if 0 <= i < grid_size and 0 <= j < grid_size and 0 <= k < grid_size and ch is not None:\n",
    "            grid[ch, i, j, k] = 1.0\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79e3d1e5-fb5f-4bee-a1cf-d2492bbd7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label_grid(water_list, center, grid_size=32, voxel_size=1.0):\n",
    "    label = np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8)\n",
    "    half = grid_size * voxel_size / 2\n",
    "    for pos, _ in water_list:\n",
    "        x, y, z = pos - center + half\n",
    "        i, j, k = (int(x // voxel_size), int(y // voxel_size), int(z // voxel_size))\n",
    "        if 0 <= i < grid_size and 0 <= j < grid_size and 0 <= k < grid_size:\n",
    "            label[i, j, k] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e853aba-1d5f-4918-9224-305d78f7c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample_with_ligand(prot_pdb, hs_pdb, lig_pdb):\n",
    "    prot_atoms = get_structure_coords(prot_pdb)\n",
    "    water_atoms = get_structure_coords(hs_pdb)\n",
    "    center = get_center_ligand(lig_pdb)\n",
    "\n",
    "    voxel_X = make_voxel_grid(prot_atoms, center)\n",
    "    voxel_Y = make_label_grid(water_atoms, center)\n",
    "\n",
    "    return voxel_X, voxel_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8363db0-0118-4937-9124-bec7053fe142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32, 32, 32)\n",
      "(32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "prot_file = \"/Users/yeonji/Dropbox/myfolder_data/wbp_last/ahr_eq/avg/xiap_ahr_eq_l20_avg.pdb\"\n",
    "hs_file = \"/Users/yeonji/Dropbox/myfolder_data/wbp_last/ahr_eq/cc/xiap_ahr_eq_cc.pdb\"\n",
    "lig_file = \"/Users/yeonji/Dropbox/myfolder_data/Binding_Site_Reorganization/min_ahr_aligned/ahr_aligned_complex/lig/xiap_lig_min_ahr_aligned.pdb\"\n",
    "X, Y = prepare_sample_with_ligand(prot_file, hs_file, lig_file)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2dc15-0da8-42d4-a337-1dcba0855b3b",
   "metadata": {},
   "source": [
    "3. PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "623a228d-2a5d-427e-856e-c857a804bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HydrationDataset(Dataset):\n",
    "    def __init__(self, prot_list, hs_list, lig_list):\n",
    "        self.prot_list = prot_list\n",
    "        self.hs_list = hs_list\n",
    "        self.lig_list = lig_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prot_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, Y = prepare_sample_with_ligand(self.prot_list[idx], self.hs_list[idx], self.lig_list[idx])\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        Y = torch.tensor(Y, dtype=torch.float32).unsqueeze(0)    # (1, D, H, W)\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c763c9-2089-44b8-a736-b1b64e0dfadd",
   "metadata": {},
   "source": [
    "4. 3D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87245032-cbf5-4a5a-b8f8-7ddf0f9d145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class HydrationCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, 3, padding=1),      # 5 -> 32 channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),                               # downsampling 32 to 16 (voxel not channel)\n",
    "\n",
    "            nn.Conv3d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "\n",
    "            nn.Conv3d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose3d(128, 64, 2, stride=2),      # Upsampling (8->16)\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose3d(64, 32, 2, stride=2),       # 16->32\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(32, 1, 1),                           # 1 channel: possibility of HS each voxel\n",
    "            nn.Sigmoid()                                   # 0-1 possibility\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952bc528-e6a9-4fae-8fea-5295c80828f3",
   "metadata": {},
   "source": [
    "5. Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22d1f71a-8455-49c7-beca-d99d771d0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cpu\")\n",
    "def train_model(model, dataloader, epochs=10, lr=1e-3, device=\"cpu\"):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCELoss()                                 # Binary Cross Entropy, HS or not-> binary\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0                                     # initialize loss as 0 each epoch\n",
    "        for X, Y in dataloader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, Y)\n",
    "            \n",
    "            optimizer.zero_grad()                            # initialize prev gradient \n",
    "            loss.backward()                                  # calculate gradient for current loss (back propagation)\n",
    "            optimizer.step()                                 # update model parameters\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13b86095-b8bc-4639-9f70-44ac4afa9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def vis_predictions(model, dataset, index=0):\n",
    "    model.eval()\n",
    "    X, Y = dataset[index]\n",
    "    with torch.no_grad():                                    # not training, grad off\n",
    "        pred = model(X.unsqueeze(0)).squeeze(0).squeeze(0).numpy()        # add bach dim (unsqueeze), squeeze & squeeze -> 3D\n",
    "        true = Y.squeeze(0).numpy()\n",
    "        \n",
    "    z = pred.shape[2] // 2\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(pred[:, :, z], cmap='hot')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(true[:, :, z], cmap='hot')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d5ee5cb-c231-4952-97db-fd45e8885c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "prot_file = sorted(glob.glob(\"/Users/yeonji/Dropbox/myfolder_data/wbp_last/ahr_eq/avg/*.pdb\"))\n",
    "hs_file = sorted(glob.glob(\"/Users/yeonji/Dropbox/myfolder_data/wbp_last/ahr_eq/cc/*.pdb\"))\n",
    "lig_file = sorted(glob.glob(\"/Users/yeonji/Dropbox/myfolder_data/Binding_Site_Reorganization/min_ahr_aligned/ahr_aligned_complex/lig/*.pdb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0428f8c6-fd6d-4e3d-b963-ac5d220ee63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HydrationDataset(prot_file, hs_file, lig_file)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d35e3b8-ae8d-4579-a9ad-181485ea312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HydrationCNN(in_channels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a6a11452-afae-4058-907e-9e32eb3a84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.2219\n",
      "Epoch 2/10 | Loss: 0.0516\n",
      "Epoch 3/10 | Loss: 0.0540\n",
      "Epoch 4/10 | Loss: 0.0540\n",
      "Epoch 5/10 | Loss: 0.0539\n",
      "Epoch 6/10 | Loss: 0.0536\n",
      "Epoch 7/10 | Loss: 0.0533\n",
      "Epoch 8/10 | Loss: 0.0530\n",
      "Epoch 9/10 | Loss: 0.0526\n",
      "Epoch 10/10 | Loss: 0.0523\n"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "19ae4795-782f-428b-86ec-3ba42bf7e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_as_pdb_real(pred, center, file_name, threshold=0.5, spacing=1.0):\n",
    "\n",
    "    output_path = \"/Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/\"\n",
    "    grid_size = np.array(pred.shape)  # (32, 32, 32)\n",
    "    half_grid = grid_size / 2.0\n",
    "\n",
    "    coords = np.argwhere(pred > threshold)  # (i, j, k) 인덱스 리스트\n",
    "\n",
    "    with open(output_path + file_name, 'w') as f:\n",
    "        for i, (x_idx, y_idx, z_idx) in enumerate(coords):\n",
    "            # voxel index를 real-world coordinate로 변환\n",
    "            fx = center[0] + (x_idx - half_grid[0]) * spacing\n",
    "            fy = center[1] + (y_idx - half_grid[1]) * spacing\n",
    "            fz = center[2] + (z_idx - half_grid[2]) * spacing\n",
    "\n",
    "            f.write(\n",
    "                f\"HETATM{i:5d}  O   HOH A{i%10000:4d}    {fx:8.3f}{fy:8.3f}{fz:8.3f}  1.00 20.00           O\\n\"\n",
    "            )\n",
    "    print(f\"PDB saved to {output_path} with real-world coordinates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8a792-2537-4975-9413-c94513ffe6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6f1524f-505f-4fb3-a5a3-f30416517278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n",
      "PDB saved to /Users/yeonji/Desktop/ComputerProject/CNN_HS_Predict/3d_CNN_HS_preds/threshold0.5/ with real-world coordinates.\n"
     ]
    }
   ],
   "source": [
    "for i, prot in enumerate(prot_file):\n",
    "    prot_name = prot.split(\"/\")[-1].split(\"_\")[0]\n",
    "    file_name = prot_name + \"_hs_pred.pdb\"\n",
    "    for lig in lig_file:\n",
    "        if prot_name in lig:\n",
    "            center = get_ligand_center(lig)\n",
    "            X, Y = dataset[i]\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(X.unsqueeze(0)).squeeze(0).squeeze(0).numpy()\n",
    "    save_prediction_as_pdb_real(pred, center, file_name, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74c81d-db1a-4953-8312-e2a4392332b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML_AI)",
   "language": "python",
   "name": "ml_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
