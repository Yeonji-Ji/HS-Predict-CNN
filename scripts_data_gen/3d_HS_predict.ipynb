{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84893b22-53af-41d1-a2c1-ccb7ebbf2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio.PDB import PDBParser\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c979618c-2aed-43f0-9415-23cc144c549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOXEL_SIZE = 1.0  # Å\n",
    "GRID_SIZE = 32  # 32x32x32\n",
    "ATOM_TYPES = ['C', 'N', 'O', 'S']  # 주요 원자 종류 (채널)\n",
    "CHANNELS = len(ATOM_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0358a508-a3be-4f51-aec2-52c440e89c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atom_channel(atom_name):\n",
    "    for i, t in enumerate(ATOM_TYPES):\n",
    "        if atom_name.startswith(t):\n",
    "            return i\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e3b89f-9805-44fa-bb45-f273eae14dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure_coords(pdb_file):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('mol', pdb_file)\n",
    "    atoms = []\n",
    "    for atom in structure.get_atoms():\n",
    "        pos = atom.get_coord()\n",
    "        name = atom.element.strip()\n",
    "        atoms.append((pos, name))\n",
    "    return atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b554c664-0f25-4ecf-a7ee-214a4e95269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ligand_center(ligand_pdb_path, ligand_resname='UNK'):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('ligand', ligand_pdb_path)\n",
    "    \n",
    "    coords = []\n",
    "    \n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                if residue.get_resname() == ligand_resname:\n",
    "                    for atom in residue:\n",
    "                        coords.append(atom.coord)\n",
    "\n",
    "    if len(coords) == 0:\n",
    "        raise ValueError(f\"No ligand atoms found with resname {ligand_resname}\")\n",
    "    \n",
    "    coords = np.array(coords)\n",
    "    center = coords.mean(axis=0)\n",
    "    \n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d37749f-95d0-4a23-9488-479332c0be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_voxel_grid(atom_list, center, grid_size=32, voxel_size=1.0):\n",
    "    # grid 0으로 초기화\n",
    "    grid = np.zeros((CHANNELS, grid_size, grid_size, grid_size), dtype=np.float32)\n",
    "    half = grid_size * voxel_size / 2\n",
    "    for pos, name in atom_list:\n",
    "        x, y, z = pos - center + half\n",
    "        i, j, k = (int(x//voxel_size), int(y//voxel_size), int(z//voxel_size))    #위치 좌표를 grid index로 변환\n",
    "        ch = get_atom_channel(name)\n",
    "        if 0 <= i < grid_size and 0 <= j < grid_size and 0 <= k < grid_size and ch is not None:\n",
    "            grid[ch, i, j, k] = 1.0\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79e3d1e5-fb5f-4bee-a1cf-d2492bbd7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label_grid(water_list, center, grid_size=32, voxel_size=1.0):\n",
    "    label = np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8)\n",
    "    half = grid_size * voxel_size / 2\n",
    "    for pos, _ in water_list:\n",
    "        x, y, z = pos - center + half\n",
    "        i, j, k = (int(x // voxel_size), int(y // voxel_size), int(z // voxel_size))\n",
    "        if 0 <= i < grid_size and 0 <= j < grid_size and 0 <= k < grid_size:\n",
    "            label[i, j, k] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e853aba-1d5f-4918-9224-305d78f7c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample_with_ligand(prot_pdb, hs_pdb, lig_pdb):\n",
    "    prot_atoms = get_structure_coords(prot_pdb)\n",
    "    water_atoms = get_structure_coords(hs_pdb)\n",
    "    center = get_ligand_center(lig_pdb)\n",
    "\n",
    "    voxel_X = make_voxel_grid(prot_atoms, center)\n",
    "    voxel_Y = make_label_grid(water_atoms, center)\n",
    "\n",
    "    return voxel_X, voxel_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2dc15-0da8-42d4-a337-1dcba0855b3b",
   "metadata": {},
   "source": [
    "3. PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "623a228d-2a5d-427e-856e-c857a804bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HydrationDataset(Dataset):\n",
    "    def __init__(self, prot_list, hs_list, lig_list):\n",
    "        self.prot_list = prot_list\n",
    "        self.hs_list = hs_list\n",
    "        self.lig_list = lig_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prot_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, Y = prepare_sample_with_ligand(self.prot_list[idx], self.hs_list[idx], self.lig_list[idx])\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        Y = torch.tensor(Y, dtype=torch.float32).unsqueeze(0)    # (1, D, H, W)\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c763c9-2089-44b8-a736-b1b64e0dfadd",
   "metadata": {},
   "source": [
    "4. 3D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87245032-cbf5-4a5a-b8f8-7ddf0f9d145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class HydrationCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, 3, padding=1),      # 5 -> 32 channels\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),                               # downsampling 32 to 16 (voxel not channel)\n",
    "\n",
    "            nn.Conv3d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "\n",
    "            nn.Conv3d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, 2, stride=2),      # Upsampling (4->8)\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose3d(64, 32, 2, stride=2),       # 8->16\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose3d(32, 32, 2, stride=2),       # 16->32\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(32, 1, 1),                           # 1 channel: possibility of HS each voxel\n",
    "            # nn.Sigmoid()                                   # 0-1 possibility\n",
    "            \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952bc528-e6a9-4fae-8fea-5295c80828f3",
   "metadata": {},
   "source": [
    "5. Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22d1f71a-8455-49c7-beca-d99d771d0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cpu\")\n",
    "def train_model(model, dataloader, epochs=50, lr=1e-3, device=\"cpu\"):\n",
    "    model = model.to(device)\n",
    "    pos_weight = torch.tensor([10.0]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # Binary Cross Entropy, HS or not-> binary\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0                                     # initialize loss as 0 each epoch\n",
    "        for X, Y in dataloader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, Y)\n",
    "            \n",
    "            optimizer.zero_grad()                            # initialize prev gradient \n",
    "            loss.backward()                                  # calculate gradient for current loss (back propagation)\n",
    "            optimizer.step()                                 # update model parameters\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13b86095-b8bc-4639-9f70-44ac4afa9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def vis_predictions(model, dataset, index=0):\n",
    "    model.eval()\n",
    "    X, Y = dataset[index]\n",
    "    with torch.no_grad():                                    # not training, grad off\n",
    "        pred = model(X.unsqueeze(0)).squeeze(0).squeeze(0).numpy()        # add bach dim (unsqueeze), squeeze & squeeze -> 3D\n",
    "        true = Y.squeeze(0).numpy()\n",
    "        \n",
    "    z = pred.shape[2] // 2\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(pred[:, :, z], cmap='hot')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(true[:, :, z], cmap='hot')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27a37962-e46c-4b68-8026-dc6de79b2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "rigid_file = sorted(glob.glob(\"/Users/yeonji/Dropbox/myfolder_data/wbp_last/ahr_eq/avg/*.pdb\"))\n",
    "rigid_hs_file = sorted(glob.glob(\"/Users/yeonji/Dropbox/myfolder_data/wbp_last/ahr_eq/cc/*.pdb\"))\n",
    "rigid_lig_file = sorted(glob.glob(\"/Users/yeonji/Dropbox/myfolder_data/Binding_Site_Reorganization/min_ahr_aligned/ahr_aligned_complex/lig/*.pdb\"))\n",
    "\n",
    "flex_file = sorted(glob.glob(\"/Users/yeonji/Dropbox/myfolder_data/wbp_last/bbr_avg_l20/*.pdb\"))\n",
    "flex_hs_file = sorted(glob.glob(\"/Users/yeonji/Dropbox/myfolder_data/wbp_last/bbr_cc/*.pdb\"))\n",
    "flex_lig_file = sorted(glob.glob(\"/Users/yeonji/Dropbox/myfolder_data/Binding_Site_Reorganization/min_ahr_aligned/bbr_aligned_complex/lig/*.pdb\"))\n",
    "\n",
    "prot_file = rigid_file + flex_file\n",
    "hs_file = rigid_hs_file + flex_hs_file\n",
    "lig_file = rigid_lig_file + flex_lig_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7e3ac19-cdbe-4d27-be79-213492230fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "68\n",
      "34\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(hs_file))\n",
    "print(len(prot_file))\n",
    "print(len(flex_file))\n",
    "print(len(lig_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0428f8c6-fd6d-4e3d-b963-ac5d220ee63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HydrationDataset(prot_file, hs_file, lig_file)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d35e3b8-ae8d-4579-a9ad-181485ea312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HydrationCNN(in_channels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6a11452-afae-4058-907e-9e32eb3a84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Loss: 0.1701\n",
      "Epoch 2/50 | Loss: 0.0567\n",
      "Epoch 3/50 | Loss: 0.0426\n",
      "Epoch 4/50 | Loss: 0.0412\n",
      "Epoch 5/50 | Loss: 0.0405\n",
      "Epoch 6/50 | Loss: 0.0406\n",
      "Epoch 7/50 | Loss: 0.0401\n",
      "Epoch 8/50 | Loss: 0.0409\n",
      "Epoch 9/50 | Loss: 0.0401\n",
      "Epoch 10/50 | Loss: 0.0396\n",
      "Epoch 11/50 | Loss: 0.0400\n",
      "Epoch 12/50 | Loss: 0.0390\n",
      "Epoch 13/50 | Loss: 0.0397\n",
      "Epoch 14/50 | Loss: 0.0381\n",
      "Epoch 15/50 | Loss: 0.0379\n",
      "Epoch 16/50 | Loss: 0.0372\n",
      "Epoch 17/50 | Loss: 0.0364\n",
      "Epoch 18/50 | Loss: 0.0355\n",
      "Epoch 19/50 | Loss: 0.0348\n",
      "Epoch 20/50 | Loss: 0.0343\n",
      "Epoch 21/50 | Loss: 0.0343\n",
      "Epoch 22/50 | Loss: 0.0339\n",
      "Epoch 23/50 | Loss: 0.0325\n",
      "Epoch 24/50 | Loss: 0.0323\n",
      "Epoch 25/50 | Loss: 0.0313\n",
      "Epoch 26/50 | Loss: 0.0304\n",
      "Epoch 27/50 | Loss: 0.0305\n",
      "Epoch 28/50 | Loss: 0.0294\n",
      "Epoch 29/50 | Loss: 0.0291\n",
      "Epoch 30/50 | Loss: 0.0285\n",
      "Epoch 31/50 | Loss: 0.0275\n",
      "Epoch 32/50 | Loss: 0.0266\n",
      "Epoch 33/50 | Loss: 0.0261\n",
      "Epoch 34/50 | Loss: 0.0251\n",
      "Epoch 35/50 | Loss: 0.0241\n",
      "Epoch 36/50 | Loss: 0.0243\n",
      "Epoch 37/50 | Loss: 0.0229\n",
      "Epoch 38/50 | Loss: 0.0212\n",
      "Epoch 39/50 | Loss: 0.0213\n",
      "Epoch 40/50 | Loss: 0.0202\n",
      "Epoch 41/50 | Loss: 0.0200\n",
      "Epoch 42/50 | Loss: 0.0200\n",
      "Epoch 43/50 | Loss: 0.0183\n",
      "Epoch 44/50 | Loss: 0.0179\n",
      "Epoch 45/50 | Loss: 0.0165\n",
      "Epoch 46/50 | Loss: 0.0166\n",
      "Epoch 47/50 | Loss: 0.0155\n",
      "Epoch 48/50 | Loss: 0.0145\n",
      "Epoch 49/50 | Loss: 0.0138\n",
      "Epoch 50/50 | Loss: 0.0136\n"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19ae4795-782f-428b-86ec-3ba42bf7e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_as_pdb_real(pred, center, output_path, file_name, threshold=0.5, spacing=1.0):\n",
    "\n",
    "    grid_size = np.array(pred.shape)  # (32, 32, 32)\n",
    "    half_grid = grid_size / 2.0\n",
    "\n",
    "    coords = np.argwhere(pred > threshold)  # (i, j, k) 인덱스 리스트\n",
    "\n",
    "    with open(output_path + file_name, 'w') as f:\n",
    "        for i, (x_idx, y_idx, z_idx) in enumerate(coords):\n",
    "            # voxel index를 real-world coordinate로 변환\n",
    "            fx = center[0] + (x_idx - half_grid[0]) * spacing\n",
    "            fy = center[1] + (y_idx - half_grid[1]) * spacing\n",
    "            fz = center[2] + (z_idx - half_grid[2]) * spacing\n",
    "\n",
    "            f.write(\n",
    "                f\"HETATM{i:5d}  O   HOH A{i%10000:4d}    {fx:8.3f}{fy:8.3f}{fz:8.3f}  1.00 20.00           O\\n\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6f1524f-505f-4fb3-a5a3-f30416517278",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, prot in enumerate(prot_file):\n",
    "    prot_name = prot.split(\"/\")[-1].split(\"_\")[0]\n",
    "    rest = prot.split(\"/\")[-1].split(\"_\")[1]\n",
    "    output_path = \"/Users/yeonji/Desktop/ComputerProject/HS-Predict-CNN/3d_CNN_HS_preds/64sys_deepCNN_0.7/\"\n",
    "    file_name = prot_name + \"_\" + rest + \"_hs_pred.pdb\"\n",
    "    for lig in lig_file:\n",
    "        if prot_name in lig:\n",
    "            center = get_ligand_center(lig)\n",
    "            X, Y = dataset[i]\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(X.unsqueeze(0))\n",
    "                pred = torch.sigmoid(pred)\n",
    "                pred = pred.squeeze(0).squeeze(0).numpy()\n",
    "    save_prediction_as_pdb_real(pred, center, output_path, file_name, threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb74c81d-db1a-4953-8312-e2a4392332b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(pred, true, threshold=0.5):\n",
    "\n",
    "    pred_bin = (pred > threshold).astype(np.uint8)\n",
    "    true_bin = (true > 0.5).astype(np.uint8)  # ground truth가 0 또는 1이라면 이대로\n",
    "\n",
    "    TP = np.sum((pred_bin == 1) & (true_bin == 1))\n",
    "    FP = np.sum((pred_bin == 1) & (true_bin == 0))\n",
    "    FN = np.sum((pred_bin == 0) & (true_bin == 1))\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    iou = TP / (TP + FP + FN + 1e-8)\n",
    "\n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'IoU': iou\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5acce918-aaad-4829-b359-656c227efe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': np.float64(0.15789473682548477), 'Recall': np.float64(0.7142857139455782), 'F1 Score': np.float64(0.2586206866453627), 'IoU': np.float64(0.14851485147044408)}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(X.unsqueeze(0))\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = pred.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "true = Y.squeeze(0).cpu().numpy()\n",
    "\n",
    "metrics = evaluate_prediction(pred, true, threshold=0.5)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad152fd3-401f-464b-9b70-4d88e13d8b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML_AI)",
   "language": "python",
   "name": "ml_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
